---
title: "Trial"
author: "Niteshyadav sanna"
date: "02-25-2024"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
```


***QUESTION***
Universal bank is a young bank growing rapidly in terms of overall customer acquisition. The majority of these customers are liability customers (depositors) with varying sizes of relationship with the bank. The customer base of asset customers (borrowers) is quite small, and the bank is interested in expanding this base rapidly in more loan business. In particular, it wants to explore ways of converting its liability customers to personal loan customers.

A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over 9% success. This has encouraged the retail marketing department to devise smarter campaigns with better target marketing. The goal is to use k-NN to predict whether a new customer will accept a loan offer. This will serve as the basis for the design of a new campaign.

The file UniversalBank.csv contains data on 5000 customers. The data include customer
demographic information (age, income, etc.), the customerâ€™s relationship with the bank
(mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign.

Partition the data into training (60%) and validation (40%) sets.

Consider the following customer:


1. Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2,
Education_1 = 0, Education_2 = 1, Education_3 = 0, 
Mortgage = 0, Securities Account = 0, CD Account = 0, 
Online = 1, and Credit Card = 1. 
Perform a k-NN classification with all predictors except ID and ZIP code
using k = 1. 
Remember to transform categorical predictors with more than two categories
into dummy variables first. Specify the success class as 1 (loan acceptance), and use the default cutoff value of 0.5. 
How would this customer be classified?


2. What is a choice of k that balances between overfitting and 
ignoring the predictor information?

3. Show the confusion matrix for the validation data 
that results from using the best k.

4. Consider the following customer: Age = 40, Experience = 10, Income = 84,
Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3 = 0,
Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1 and Credit
Card = 1. Classify the customer using the best k.


5. Repartition the data, this time into training, validation, and 
test sets (50% : 30% : 20%). Apply the k-NN method with the k chosen above. 
Compare the confusion matrix of the test set with that of the training and
validation sets. Comment on the differences and their reason.


***SOLUTION***

First, let us load all the required libraries for this assignment
```{r}
library(caret)
library(class)
library(dplyr)
library(ISLR)
library(ggplot2)
library(fastDummies)
library(FNN)
library(psych)
library(e1071)
library(readr)
```

Now, we import the data and then change the levels of the column 'Personal.Loan' from 0 and 1 to No and Yes, respectively. We do this to make it easier for us to proceed with the further process.
```{r}
#I would like to mention that I changed the column name
#of 'Personal Loan' to 'Personal.Loan' to make it readible for the R directory.
BankInfo <- read.csv("C:/Users/sanna/OneDrive/Desktop/FML/UniversalBank.csv")
BankInfo$Personal.Loan<-factor(BankInfo$Personal.Loan,levels=c('0','1'),labels=c('No','Yes'))
summary(BankInfo)
```
**Data Selection**

Here, we do the data selection and data partition with 60% as training data and the rest 40% for testing data
```{r}
dummy_BankInfo <- dummy_columns(BankInfo, select_columns = 'Education')
m_BankInfo <- select(dummy_BankInfo,Age,
                     Experience,
                     Income,
                     Family,
                     CCAvg,
                     Education_1,
                     Education_2,
                     Education_3,
                     Mortgage,
                     Personal.Loan,
                     Securities.Account,
                     CD.Account,
                     Online,
                     CreditCard)
m_BankInfo <- m_BankInfo %>% relocate(Personal.Loan,.after=last_col())
#Personal loan should be placed to the end of the list to make work easier later.
set.seed(1)
Train_Index <- sample(row.names(m_BankInfo), 0.6*dim(m_BankInfo)[1])
Val_Index <- setdiff(row.names(m_BankInfo), Train_Index)
Train_Data <- m_BankInfo[Train_Index,]
Validation_Data <- m_BankInfo[Val_Index,]
summary(Train_Data)
```
**TRAINING DATA**
```{r}
columnsare <-c(1,2,3,4,5,9)
BankInfo.norm.df <- m_BankInfo
train.norm.df <- Train_Data
valid.norm.df <- Validation_Data
norm.values <- preProcess(Train_Data[,columnsare], method=c("center","scale"))
train.norm.df[, columnsare] <-predict(norm.values,Train_Data[,columnsare])
valid.norm.df[, columnsare] <-predict(norm.values,Validation_Data[,columnsare])
summary(train.norm.df)
```

**k-NN CLASSIFICATION**
```{r}
train.knn.predictors <- train.norm.df[, 1:13]
train.knn.success <-train.norm.df[,14]
valid.knn.predictors <- valid.norm.df[, 1:13]
valid.knn.success <-valid.norm.df[,14]
knn.results <- knn (train=train.knn.predictors, 
                    test=valid.knn.predictors, 
                    cl=train.knn.success, 
                    k=1, prob=TRUE)
confusionMatrix(knn.results,valid.knn.success, positive="Yes")
```
**As depicted above the model is 96.1% accurate, which can be considered a fairly good percentage of accuracy.**

k=1

**The next step is to predict the class of a consumer who has the characterstics as following:**

Age = 40,
Experience = 10,
Income = 84,
Family = 2,
CCAvg = 2,
Education_1 = 0,
Education_2 = 1,
Education_3 = 0, 
Mortgage = 0, 
Securities Account = 0, 
CD Account = 0,
Online = 1, 
and 
Credit Card = 1

```{r}
customertest = data.frame(Age = as.integer(40), 
                          Experience = as.integer(10), 
                          Income = as.integer(84), 
                          Family = as.integer(2), 
                          CCAvg = as.integer(2), 
                          Education1 = as.integer(0), 
                          Education2 = as.integer(1), 
                          Education3 = as.integer(0), 
                          Mortgage = as.integer(0), 
                          Securities.Account = as.integer(0), 
                          CD.Account = as.integer(0), 
                          Online = as.integer(1), 
                          CreditCard = as.integer(1))
#Now we load the data into a customertest dataframe and we normalize this data.
customer.norm.df <- customertest
customer.norm.df[, columnsare]<-predict(norm.values,customertest[,columnsare])
```


```{r}
#Now let us do a prediction test with previously used k-NN classification
set.seed(123)
customer.knn <- knn(train=train.knn.predictors,
                    test=customer.norm.df,
                    cl=train.knn.success,
                    k=1, prob=TRUE) 
#Calculating the knn for customer.
head(customer.knn)
```

```{r}
# we have to Calculate the accuracy for each value of k
# Set the range of k values to consider with following commands.
#TUNING USING VALIDATION
accuracy.df <- data.frame(k = seq(1,14,1), accuracy = rep(0 , 14))

#Now we will make a table with all of the k and their accuracies from 1 to 14.
for(i in 1:14){knn.pred <- knn(train.knn.predictors,
                               valid.knn.predictors, 
                               cl=train.knn.success,k=i)
accuracy.df[i,2] <- confusionMatrix(knn.pred, valid.knn.success)$overall[1]
}

accuracy.df
```

```{r}
which.max(accuracy.df$accuracy)
```

```{r}
plot(accuracy.df$k,accuracy.df$overallaccuracy)
```



```{r}
customer.knn3 <- knn(train=train.knn.predictors,
                     test=customer.norm.df,
                     cl=train.knn.success,
                     k=3, prob=TRUE)
head(customer.knn3)
```

**Further examination of k = 3**


**A confusion matrix of the validation data for k=3 is shown below**

```{r}
knn.k3 <- knn(train = train.knn.predictors,
              test=valid.knn.predictors,
              cl=train.knn.success,
              k=3, prob=TRUE)
confusionMatrix(knn.k3,valid.knn.success,)
```


**Repartitioning for a test set**
```{r}
set.seed(500)
Train_Index <- sample(row.names(m_BankInfo), .5*dim(m_BankInfo)[1])
#create train index
Val_Index <- sample(setdiff(row.names(m_BankInfo),Train_Index),.3*dim(m_BankInfo)[1])
#create validation index
Test_Index =setdiff(row.names(m_BankInfo),union(Train_Index,Val_Index))
#create test index
#load the data
Train_Data <- m_BankInfo[Train_Index,]
Validation_Data <- m_BankInfo[Val_Index,]
Test_Data <- m_BankInfo [Test_Index,]
#normalize the quantitative data
norm.values3 <- preProcess(m_BankInfo[,columnsare], method=c("center", "scale"))
train.norm.df3 = Train_Data
val.norm.df3 = Validation_Data
test.norm.df3 = Test_Data
train.norm.df3[, columnsare] <- predict(norm.values3, Train_Data[, columnsare])
val.norm.df3[, columnsare] <- predict(norm.values3, Validation_Data[, columnsare])
test.norm.df3[, columnsare] <- predict(norm.values3, Test_Data[, columnsare])
#run knn for all 3
knn.train <- knn(train=train.norm.df3[,-14],
                 test=train.norm.df3[,-14],
                 cl=train.norm.df3[,14], 
                 k=3, prob=TRUE)
knn.val<- knn(train=train.norm.df3[,-14],
              test=val.norm.df3[,-14],
              cl=train.norm.df3[,14],
              k=3, prob=TRUE)
knn.test<- knn(train=train.norm.df3[,-14],
               test=test.norm.df3[,-14],
               cl=train.norm.df3[,14],
               k=3, prob=TRUE)
#display the confusion matrices
confusionMatrix(knn.train,train.norm.df3[,14], positive="Yes")
```

```{r}
confusionMatrix(knn.val,val.norm.df3[,14], positive="Yes")
```


```{r}
confusionMatrix(knn.test,test.norm.df3[,14], positive="Yes")
```












